# ¬ß3.6 Linear Difference Equations

:::{note}
**Keywords:**

[difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations) , [numerical solution](http://dlmf.nist.gov/search/search?q=numerical%20solution)

**Referenced by:**

¬ß11.13(v) , ¬ß14.32 , ¬ß18.40(i) , item (d) , ¬ß29.20(i) , Ch.3 , ¬ß30.16(ii) , ¬ß33.23(iv)

**See also:**

Annotations for Ch.3
:::


## ¬ß3.6(i) Introduction

:::{note}
**Defines:**

$\Delta$ : forward difference operator

**Referenced by:**

¬ß2.9(i) , ¬ß26.8(v)

**See also:**

Annotations for ¬ß3.6 and Ch.3
:::

Many special functions satisfy second-order recurrence relations, or difference equations, of the form


<a id="E1"></a>
$$
a_{n}w_{n+1}-b_{n}w_{n}+c_{n}w_{n-1}=d_{n}, \tag{3.6.1}
$$

or equivalently,


<a id="E2"></a>
$$
a_{n}\Delta^{2}w_{n-1}+(2a_{n}-b_{n})\Delta w_{n-1}+(a_{n}-b_{n}+c_{n})w_{n-1}=d_{n}, \tag{3.6.2}
$$

where $\Delta w_{n-1}=w_{n}-w_{n-1}$ , $\Delta^{2}w_{n-1}=\Delta w_{n}-\Delta w_{n-1}$ , and $n\in\mathbb{Z}$ . If $d_{n}=0$ , $\forall n$ , then the difference equation is *homogeneous* ; otherwise it is *inhomogeneous* .

Difference equations are simple and attractive for computation. In practice, however, problems of severe instability often arise and in ¬ß¬ß 3.6(ii) ‚Äì 3.6(vii) we show how these difficulties may be overcome.


## ¬ß3.6(ii) Homogeneous Equations

:::{note}
**Keywords:**

[backward recursion](http://dlmf.nist.gov/search/search?q=backward%20recursion) , [backward recursion method](http://dlmf.nist.gov/search/search?q=backward%20recursion%20method) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations) , [distinguished solutions](http://dlmf.nist.gov/search/search?q=distinguished%20solutions) , [homogeneous equations](http://dlmf.nist.gov/search/search?q=homogeneous%20equations) , [minimal solutions](http://dlmf.nist.gov/search/search?q=minimal%20solutions) , [numerical solution](http://dlmf.nist.gov/search/search?q=numerical%20solution) , [recessive solutions](http://dlmf.nist.gov/search/search?q=recessive%20solutions) , [stability](http://dlmf.nist.gov/search/search?q=stability)

**Referenced by:**

¬ß15.19(iv) , ¬ß3.6(i)

**See also:**

Annotations for ¬ß3.6 and Ch.3
:::

Given numerical values of $w_{0}$ and $w_{1}$ , the solution $w_{n}$ of the equation


<a id="E3"></a>
$$
a_{n}w_{n+1}-b_{n}w_{n}+c_{n}w_{n-1}=0, \tag{3.6.3}
$$

with $a_{n}\neq 0$ , $\forall n$ , can be computed recursively for $n=2,3,\dots$ . Unless exact arithmetic is being used, however, each step of the calculation introduces rounding errors. These errors have the effect of perturbing the solution by unwanted small multiples of $w_{n}$ and of an independent solution $g_{n}$ , say. This is of little consequence if the wanted solution is growing in magnitude at least as fast as any other solution of ( 3.6.3 ), and the recursion process is *stable* .

But suppose that $w_{n}$ is a nontrivial solution such that


<a id="E4"></a>
$$
w_{n}/g_{n}\to 0, \tag{3.6.4}
$$

Then $w_{n}$ is said to be a *recessive* (equivalently, *minimal* or *distinguished* ) *solution* as $n\to\infty$ , and it is unique except for a constant factor. In this situation the unwanted multiples of $g_{n}$ grow more rapidly than the wanted solution, and the computations are *unstable* . Stability can be restored, however, by *backward recursion* , provided that $c_{n}\neq 0$ , $\forall n$ : starting from $w_{N}$ and $w_{N+1}$ , with $N$ large, equation ( 3.6.3 ) is applied to generate in succession $w_{N-1},w_{N-2},\dots,w_{0}$ . The unwanted multiples of $g_{n}$ now decay in comparison with $w_{n}$ , hence are of little consequence.

The values of $w_{N}$ and $w_{N+1}$ needed to begin the backward recursion may be available, for example, from asymptotic expansions (¬ß [2.9](./2.9.md "¬ß2.9 Difference Equations ‚Ä£ Areas ‚Ä£ Chapter 2 Asymptotic Approximations") ). However, there are alternative procedures that do not require $w_{N}$ and $w_{N+1}$ to be known in advance. These are described in ¬ß¬ß 3.6(iii) and 3.6(v) .


## ¬ß3.6(iii) Miller‚Äôs Algorithm

:::{note}
**Keywords:**

[Miller‚Äôs algorithm](http://dlmf.nist.gov/search/search?q=Miller%20algorithm) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations) , [homogeneous equations](http://dlmf.nist.gov/search/search?q=homogeneous%20equations) , [normalizing factor](http://dlmf.nist.gov/search/search?q=normalizing%20factor) , [numerical solution](http://dlmf.nist.gov/search/search?q=numerical%20solution)

**Referenced by:**

¬ß3.6(vi) , ¬ß3.6(ii) , ¬ß6.18(ii)

**See also:**

Annotations for ¬ß3.6 and Ch.3
:::

Because the recessive solution of a homogeneous equation is the fastest growing solution in the backward direction, it occurred to J.C.P. Miller (Bickley et al. ([1952](./bib/B.html#bib278 "Bessel Functions. Part II: Functions of Positive Integer Order"), pp. xvi‚Äìxvii)) that arbitrary ‚Äútrial values‚Äù can be assigned to $w_{N}$ and $w_{N+1}$ , for example, $1$ and $0$ . A ‚Äútrial solution‚Äù is then computed by backward recursion, in the course of which the original components of the unwanted solution $g_{n}$ die away. It therefore remains to apply a normalizing factor $\Lambda$ . The process is then repeated with a higher value of $N$ , and the normalized solutions compared. If agreement is not within a prescribed tolerance the cycle is continued.

The normalizing factor $\Lambda$ can be the true value of $w_{0}$ divided by its trial value, or $\Lambda$ can be chosen to satisfy a known property of the wanted solution of the form


<a id="E5"></a>
$$
\sum_{n=0}^{\infty}\lambda_{n}w_{n}=1, \tag{3.6.5}
$$

where the $\lambda$ ‚Äôs are constants. The latter method is usually superior when the true value of $w_{0}$ is zero or pathologically small.

For further information on Miller‚Äôs algorithm, including examples, convergence proofs, and error analyses, see Wimp ([1984](./bib/W.html#bib2421 "Computation with Recurrence Relations"), Chapter 4), Gautschi ([1967](./bib/G.html#bib877 "Computational aspects of three-term recurrence relations"), [1997b](./bib/G.html#bib894 "The Computation of Special Functions by Linear Difference Equations")), and Olver ([1964a](./bib/O.html#bib1785 "Error analysis of Miller‚Äôs recurrence algorithm")). See also Gautschi ([1967](./bib/G.html#bib877 "Computational aspects of three-term recurrence relations")) and Gil et al. ([2007a](./bib/G.html#bib935 "Numerical Methods for Special Functions"), Chapter 4) for the computation of recessive solutions via continued fractions.


## ¬ß3.6(iv) Inhomogeneous Equations

:::{note}
**Keywords:**

[backward recursion method](http://dlmf.nist.gov/search/search?q=backward%20recursion%20method) , [boundary-value methods](http://dlmf.nist.gov/search/search?q=boundary-value%20methods) , [boundary-value methods or problems](http://dlmf.nist.gov/search/search?q=boundary-value%20methods%20or%20problems) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations) , [inhomogeneous equations](http://dlmf.nist.gov/search/search?q=inhomogeneous%20equations) , [numerical solution](http://dlmf.nist.gov/search/search?q=numerical%20solution)

**Notes:**

See Olver ([1967a](./bib/O.html#bib1790 "Numerical solution of second-order linear difference equations")).

**Referenced by:**

¬ß3.6(v)

**See also:**

Annotations for ¬ß3.6 and Ch.3
:::

Similar principles apply to equation ( 3.6.1 ) when $a_{n}c_{n}\neq 0$ , $\forall n$ , and $d_{n}\neq 0$ for some, or all, values of $n$ . If, as $n\to\infty$ , the wanted solution $w_{n}$ grows (decays) in magnitude at least as fast as any solution of the corresponding homogeneous equation, then forward (backward) recursion is stable.

A new problem arises, however, if, as $n\to\infty$ , the asymptotic behavior of $w_{n}$ is intermediate to those of two independent solutions $f_{n}$ and $g_{n}$ of the corresponding inhomogeneous equation (the complementary functions). More precisely, assume that $f_{0}\neq 0$ , $g_{n}\neq 0$ for all sufficiently large $n$ , and as $n\to\infty$

<a id="E6"></a>

<a id="Ex1"></a>
$$
\displaystyle f_{n}/g_{n} \displaystyle\to 0, \tag{3.6.6}
$$

<a id="Ex2"></a>
$$
\displaystyle w_{n}/g_{n} \displaystyle\to 0.
$$

:::{note}
**Symbols:**

$w_{n}$: sequence and $g_{n}$: solution

**See also:**

Annotations for ¬ß3.6(iv) , ¬ß3.6 and Ch.3
:::

Then computation of $w_{n}$ by forward recursion is unstable. If it also happens that $f_{n}/w_{n}\to 0$ as $n\to\infty$ , then computation of $w_{n}$ by backward recursion is unstable as well. However, $w_{n}$ can be computed successfully in these circumstances by *boundary-value methods* , as follows.

Let us assume the normalizing condition is of the form $w_{0}=\lambda$ , where $\lambda$ is a constant, and then solve the following tridiagonal system of algebraic equations for the unknowns $w_{1}^{(N)},w_{2}^{(N)},\dots,w_{N-1}^{(N)}$ ; see ¬ß 3.2(ii) . Here $N$ is an arbitrary positive integer.


<a id="E7"></a>
$$
\begin{bmatrix}-b_{1}&a_{1}&&&0\\
c_{2}&-b_{2}&a_{2}\\
&\ddots&\ddots&\ddots\\
&&c_{N-2}&-b_{N-2}&a_{N-2}\\
0&&&c_{N-1}&-b_{N-1}\end{bmatrix}\begin{bmatrix}w_{1}^{(N)}\\
w_{2}^{(N)}\\
\vdots\\
w_{N-2}^{(N)}\\
w_{N-1}^{(N)}\end{bmatrix}=\begin{bmatrix}d_{1}-c_{1}\lambda\\
d_{2}\\
\vdots\\
d_{N-2}\\
d_{N-1}\end{bmatrix}. \tag{3.6.7}
$$

Then as $N\to\infty$ with $n$ fixed, $w_{n}^{(N)}\to w_{n}$ .


## ¬ß3.6(v) Olver‚Äôs Algorithm

:::{note}
**Keywords:**

[Olver‚Äôs algorithm](http://dlmf.nist.gov/search/search?q=Olver%20algorithm) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations)

**Referenced by:**

¬ß10.74(iv) , ¬ß13.29(iv) , ¬ß3.6(vi) , ¬ß3.6(vi) , ¬ß3.6(ii) , ¬ß3.7(iii)

**See also:**

Annotations for ¬ß3.6 and Ch.3
:::

To apply the method just described a succession of values can be prescribed for the arbitrary integer $N$ and the results compared. However, a more powerful procedure combines the solution of the algebraic equations with the determination of the optimum value of $N$ . It is applicable equally to the computation of the recessive solution of the homogeneous equation ( 3.6.3 ) or the computation of any solution $w_{n}$ of the inhomogeneous equation ( 3.6.1 ) for which the conditions of ¬ß 3.6(iv) are satisfied.

Suppose again that $f_{0}\neq 0$ , $w_{0}$ is given, and we wish to calculate $w_{1},w_{2},\dots,w_{M}$ to a prescribed relative accuracy $\epsilon$ for a given value of $M$ . We first compute, by forward recurrence, the solution $p_{n}$ of the homogeneous equation ( 3.6.3 ) with initial values $p_{0}=0$ , $p_{1}=1$ . At the same time we construct a sequence $e_{n}$ , $n=0,1,\dots$ , defined by


<a id="E8"></a>
$$
a_{n}e_{n}=c_{n}e_{n-1}-d_{n}p_{n}, \tag{3.6.8}
$$

beginning with $e_{0}=w_{0}$ . (This part of the process is equivalent to forward elimination.) The computation is continued until a value $N$ ( $\geq M$ ) is reached for which


<a id="E9"></a>
$$
\left|\frac{e_{N}}{p_{N}p_{N+1}}\right|\leq\epsilon\min_{1\leq n\leq M}\left|\frac{e_{n}}{p_{n}p_{n+1}}\right|. \tag{3.6.9}
$$

Then $w_{n}$ is generated by backward recursion from


<a id="E10"></a>
$$
p_{n+1}w_{n}=p_{n}w_{n+1}+e_{n}, \tag{3.6.10}
$$

starting with $w_{N}=0$ . (This part of the process is back substitution.)

An example is included in the next subsection. For further information, including a more general form of normalizing condition, other examples, convergence proofs, and error analyses, see Olver ([1967a](./bib/O.html#bib1790 "Numerical solution of second-order linear difference equations")), Olver and Sookne ([1972](./bib/O.html#bib1812 "Note on backward recurrence algorithms")), and Wimp ([1984](./bib/W.html#bib2421 "Computation with Recurrence Relations"), Chapter 6).


## ¬ß3.6(vi) Examples

:::{note}
**See also:**

Annotations for ¬ß3.6 and Ch.3
:::


### Example 1. Bessel Functions

:::{note}
**Keywords:**

[Bessel functions](http://dlmf.nist.gov/search/search?q=Bessel%20functions) , [Miller‚Äôs algorithm](http://dlmf.nist.gov/search/search?q=Miller%20algorithm) , [computation by recursion](http://dlmf.nist.gov/search/search?q=computation%20by%20recursion) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations)

**See also:**

Annotations for ¬ß3.6(vi) , ¬ß3.6 and Ch.3
:::

The difference equation


<a id="E11"></a>
$$
w_{n+1}-2nw_{n}+w_{n-1}=0, \tag{3.6.11}
$$

is satisfied by $J_{n}\left(1\right)$ and $Y_{n}\left(1\right)$ , where $J_{n}\left(x\right)$ and $Y_{n}\left(x\right)$ are the Bessel functions of the first kind. For large $n$ ,


<a id="E12"></a>
$$
J_{n}\left(1\right)\sim\frac{1}{(2\pi n)^{1/2}}\left(\frac{e}{2n}\right)^{n}, \tag{3.6.12}
$$


<a id="E13"></a>
$$
Y_{n}\left(1\right)\sim\left(\frac{2}{\pi n}\right)^{1/2}\left(\frac{2n}{e}\right)^{n}, \tag{3.6.13}
$$

(¬ß 10.19(i) ). Thus $Y_{n}\left(1\right)$ is dominant and can be computed by forward recursion, whereas $J_{n}\left(1\right)$ is recessive and has to be computed by backward recursion. The backward recursion can be carried out using independently computed values of $J_{N}\left(1\right)$ and $J_{N+1}\left(1\right)$ or by use of Miller‚Äôs algorithm (¬ß 3.6(iii) ) or Olver‚Äôs algorithm (¬ß 3.6(v) ).


### Example 2. Weber Function

:::{note}
**Keywords:**

[Anger‚ÄìWeber functions](http://dlmf.nist.gov/search/search?q=Anger%E2%80%93Weber%20functions) , [computation](http://dlmf.nist.gov/search/search?q=computation)

**See also:**

Annotations for ¬ß3.6(vi) , ¬ß3.6 and Ch.3
:::

The Weber function $\mathbf{E}_{n}\left(1\right)$ satisfies


<a id="E14"></a>
$$
w_{n+1}-2nw_{n}+w_{n-1}=-(2/\pi)(1-(-1)^{n}), \tag{3.6.14}
$$

for $n=1,2,\dots$ , and as $n\to\infty$

<a id="EGx1"></a>

$$
\displaystyle\mathbf{E}_{2n}\left(1\right) \displaystyle\sim\frac{2}{(4n^{2}-1)\pi}, \tag{3.6.15}
$$

:::{note}
**Symbols:**

$\mathbf{E}_{\NVar{\nu}}\left(\NVar{z}\right)$: Weber function , $\sim$: asymptotic equality and $\pi$: the ratio of the circumference of a circle to its diameter

**See also:**

Annotations for ¬ß3.6(vi) , ¬ß3.6(vi) , ¬ß3.6 and Ch.3
:::

$$
\displaystyle\mathbf{E}_{2n+1}\left(1\right) \displaystyle\sim\frac{2}{(2n+1)\pi}; \tag{3.6.16}
$$

:::{note}
**Symbols:**

$\mathbf{E}_{\NVar{\nu}}\left(\NVar{z}\right)$: Weber function , $\sim$: asymptotic equality and $\pi$: the ratio of the circumference of a circle to its diameter

**See also:**

Annotations for ¬ß3.6(vi) , ¬ß3.6(vi) , ¬ß3.6 and Ch.3
:::

see ¬ß 11.11(ii) . Thus the asymptotic behavior of the particular solution $\mathbf{E}_{n}\left(1\right)$ is intermediate to those of the complementary functions $J_{n}\left(1\right)$ and $Y_{n}\left(1\right)$ ; moreover, the conditions for Olver‚Äôs algorithm are satisfied. We apply the algorithm to compute $\mathbf{E}_{n}\left(1\right)$ to 8S for the range $n=1,2,\dots,10$ , beginning with the value $\mathbf{E}_{0}\left(1\right)=-0.56865\;\,663$ obtained from the Maclaurin series expansion (¬ß 11.10(iii) ).

In the notation of ¬ß 3.6(v) we have $M=10$ and $\epsilon=\tfrac{1}{2}\times 10^{-8}$ . The least value of $N$ that satisfies ( 3.6.9 ) is found to be 16. The results of the computations are displayed in Table 3.6.1 . The values of $w_{n}$ for $n=1,2,\dots,10$ are the wanted values of $\mathbf{E}_{n}\left(1\right)$ . (It should be observed that for $n>10$ , however, the $w_{n}$ are progressively poorer approximations to $\mathbf{E}_{n}\left(1\right)$ : the underlined digits are in error.)

<a id="T1"></a>
| **$n$** | **$p_{n}$** |   | **$e_{n}$** |   | **$e_{n}/(p_{n}p_{n+1})$** |   | **$w_{n}$** |   |
|---|---|---|---|---|---|---|---|---|
| **0** | **$0.00000\;000$** |   | **$-0.56865\;663$** |   |   |   | **$-0.56865\;663$** |   |
| **1** | **$0.10000\;000$** | **$\times 10^{1}$** | **$0.70458\;291$** |   | **$0.35229\;146$** |   | **$0.43816\;243$** |   |
| **2** | **$0.20000\;000$** | **$\times 10^{1}$** | **$0.70458\;291$** |   | **$0.50327\;351$** | **$\times 10^{-1}$** | **$0.17174\;195$** |   |
| **3** | **$0.70000\;000$** | **$\times 10^{1}$** | **$0.96172\;597$** | **$\times 10^{1}$** | **$0.34347\;356$** | **$\times 10^{-1}$** | **$0.24880\;538$** |   |
| **4** | **$0.40000\;000$** | **$\times 10^{2}$** | **$0.96172\;597$** | **$\times 10^{1}$** | **$0.76815\;174$** | **$\times 10^{-3}$** | **$0.47850\;795$** | **$\times 10^{-1}$** |
| **5** | **$0.31300\;000$** | **$\times 10^{3}$** | **$0.40814\;124$** | **$\times 10^{3}$** | **$0.42199\;534$** | **$\times 10^{-3}$** | **$0.13400\;098$** |   |
| **6** | **$0.30900\;000$** | **$\times 10^{4}$** | **$0.40814\;124$** | **$\times 10^{3}$** | **$0.35924\;754$** | **$\times 10^{-5}$** | **$0.18919\;443$** | **$\times 10^{-1}$** |
| **7** | **$0.36767\;000$** | **$\times 10^{5}$** | **$0.47221\;340$** | **$\times 10^{5}$** | **$0.25102\;029$** | **$\times 10^{-5}$** | **$0.93032\;343$** | **$\times 10^{-1}$** |
| **8** | **$0.51164\;800$** | **$\times 10^{6}$** | **$0.47221\;340$** | **$\times 10^{5}$** | **$0.11324\;804$** | **$\times 10^{-7}$** | **$0.10293\;811$** | **$\times 10^{-1}$** |
| **9** | **$0.81496\;010$** | **$\times 10^{7}$** | **$0.10423\;616$** | **$\times 10^{8}$** | **$0.87496\;485$** | **$\times 10^{-8}$** | **$0.71668\;638$** | **$\times 10^{-1}$** |
| **10** | **$0.14618\;117$** | **$\times 10^{9}$** | **$0.10423\;616$** | **$\times 10^{8}$** | **$0.24457\;824$** | **$\times 10^{-10}$** | **$0.65021\;292$** | **$\times 10^{-2}$** |
| **11** | **$0.29154\;738$** | **$\times 10^{10}$** | **$0.37225\;201$** | **$\times 10^{10}$** | **$0.19952\;026$** | **$\times 10^{-10}$** | **$0.58373\;946$** | **$\times 10^{-1}$** |
| **12** | **$0.63994\;242$** | **$\times 10^{11}$** | **$0.37225\;201$** | **$\times 10^{10}$** | **$0.37946\;279$** | **$\times 10^{-13}$** | **$0.44851\;3\underline{87}$** | **$\times 10^{-2}$** |
| **13** | **$0.15329\;463$** | **$\times 10^{13}$** | **$0.19555\;304$** | **$\times 10^{13}$** | **$0.32057\;909$** | **$\times 10^{-13}$** | **$0.49269\;\underline{383}$** | **$\times 10^{-1}$** |
| **14** | **$0.39792\;611$** | **$\times 10^{14}$** | **$0.19555\;304$** | **$\times 10^{13}$** | **$0.44167\;174$** | **$\times 10^{-16}$** | **$0.327\underline{92\;861}$** | **$\times 10^{-2}$** |
| **15** | **$0.11126\;602$** | **$\times 10^{16}$** | **$0.14186\;384$** | **$\times 10^{16}$** | **$0.38242\;250$** | **$\times 10^{-16}$** | **$0.425\underline{50\;628}$** | **$\times 10^{-1}$** |
| **16** | **$0.33340\;012$** | **$\times 10^{17}$** | **$0.14186\;384$** | **$\times 10^{16}$** | **$0.39924\;861$** | **$\times 10^{-19}$** | **$0.\underline{00000\;000}$** |   |
: Table 3.6.1: Weber function w n = ùêÑ n ‚Å° ( 1 ) computed by Olver‚Äôs algorithm.

:::{note}
**Symbols:**

$\mathbf{E}_{\NVar{\nu}}\left(\NVar{z}\right)$: Weber function , $w_{n}$: sequence , $p_{n}$: solutions and $e_{n}$: sequence

**Keywords:**

[Olver‚Äôs algorithm](http://dlmf.nist.gov/search/search?q=Olver%20algorithm) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations)

**Referenced by:**

¬ß3.6(vi)

**See also:**

Annotations for ¬ß3.6(vi) , ¬ß3.6(vi) , ¬ß3.6 and Ch.3
:::


## ¬ß3.6(vii) Linear Difference Equations of Other Orders

:::{note}
**Keywords:**

[boundary-value methods](http://dlmf.nist.gov/search/search?q=boundary-value%20methods) , [boundary-value methods or problems](http://dlmf.nist.gov/search/search?q=boundary-value%20methods%20or%20problems) , [difference equations](http://dlmf.nist.gov/search/search?q=difference%20equations) , [numerical solution](http://dlmf.nist.gov/search/search?q=numerical%20solution)

**Referenced by:**

¬ß16.25 , ¬ß3.6(i)

**See also:**

Annotations for ¬ß3.6 and Ch.3
:::

Similar considerations apply to the first-order equation


<a id="E17"></a>
$$
a_{n}w_{n+1}-b_{n}w_{n}=d_{n}. \tag{3.6.17}
$$

Thus in the inhomogeneous case it may sometimes be necessary to recur backwards to achieve stability. For analyses and examples see Gautschi ([1997b](./bib/G.html#bib894 "The Computation of Special Functions by Linear Difference Equations")).

For a difference equation of order $k$ ( $\geq 3$ ),


<a id="E18"></a>
$$
a_{n,k}w_{n+k}+a_{n,k-1}w_{n+k-1}+\dots+a_{n,0}w_{n}=d_{n}, \tag{3.6.18}
$$

or for systems of $k$ first-order inhomogeneous equations, boundary-value methods are the rule rather than the exception. Typically $k-\ell$ conditions are prescribed at the beginning of the range, and $\ell$ conditions at the end. Here $\ell\in[0,k]$ , and its actual value depends on the asymptotic behavior of the wanted solution in relation to those of the other solutions. Within this framework forward and backward recursion may be regarded as the special cases $\ell=0$ and $\ell=k$ , respectively.

For further information see Wimp ([1984](./bib/W.html#bib2421 "Computation with Recurrence Relations"), Chapters 7‚Äì8), Cash and Zahar ([1994](./bib/C.html#bib459 "A Unified Approach to Recurrence Algorithms")), and Lozier ([1980](./bib/L.html#bib1476 "Numerical Solution of Linear Difference Equations")).
